app_name: "CadenceAI"
base_url: "0.0.0.0"
port: 8080
api_endpoint: "/v1/question"
content: "You are a friendly cycling coach. You always provide well-reasoned answers that are both correct and helpful. You provide short and concise answers."

# Local or remote OSS LLM
model_path: "artifacts/llama-2-7b-chat.Q2_K.gguf"
temperature: 0.7
max_tokens: 100
stream: False
n_gpu_layers: 0
n_threads: 6

# Remote vision LLM
vision_model: "gemini-pro-vision"
vision_content: "What is this?"
vision_max_output_tokens: 2048
vision_temperature: 0.4
vision_top_p: 1
vision_top_k: 32
vision_stream: True
img_path: "artifacts/IMG_4109.jpg"
img_type: "image/jpeg"

# Remote fine-tuned chat LLM
chat_model: "gpt-3.5-turbo-1106"
chat_content: ""

#chat_model: "gpt-3.5-turbo-1106"
#chat_content: "You are a friendly cycling coach. You always provide well-reasoned answers that are both correct and helpful. You provide short and concise answers."

#chat_model: "ft:gpt-3.5-turbo-1106:personal::8tfxMnXE"
#chat_content: ""

chat_temperature: 0
chat_max_tokens: 500
chat_top_p: 1
chat_frequency_penalty: 0
chat_presence_penalty: 0
